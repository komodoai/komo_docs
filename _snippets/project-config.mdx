```yaml
cloud: aws

# This is the directory that will be uploaded to the remote machine.
# Specifying '.' as shown below will use the current project directory.
# This means that every time you run a job, all of the files you have in your project directory
# (doesn't matter if they're committed with git or not) will be uploaded to the remote machine
workdir: .

# Set the environment variables you want to use here.
env:
  my_var: "my_value"

setup: |
  pip install -r requirements.txt

# Optionally add input/output storage
# Currently, only S3 buckets are supported
# storage:
#   /dataset:
#     source: s3://my-dataset
#     # the bucket contents will be copied into /dataset during setup
#     # files you write here will NOT be uploaded back to s3
#     mode: COPY
#   /output:
#     source: s3://my-output-bucket
#     # the bucket will be mounted onto /output
#     # files you write here will be uploaded back to s3
#     mode: MOUNT

# Optional docker image to be used as the base environment
# Setup and run commands will be run inside this docker environment
# docker_image: my-image:latest

# Optionally define resources for all jobs using this project config
# You can also define gpus on the fly using the --gpus CLI flag
# resources:
#   gpus: T4:1
```
